## 资源限制技巧汇总

1. 布隆过滤器用于集合的建立与查询，并可以节省大量空间
2. 一致性哈希解决数据服务器的负载管理问题
3. 利用并查集结构做岛问题的并行计算
4. 哈希函数可以把数据按照种类均匀分流
5. 位图解决某一范围上数字的出现情况，并可以节省大量空间
6. 利用分段统计思想、并进一步节省大量空间
7. 利用堆、外排序来做多个处理单元的结果合并

### 问题一：哈希问题（4）
- 32位无符号整数的范围时0~4294967295，现在有一个正好包含40亿个无符号整数的文件，
可以使用最多1GB的内存，怎么找到出现次数最多的数？   
   
   **前提**：1GB文件最多可以保存1亿个数据（大概），因为在内存中的开销不止整数，还要有哈希表用来统计数据，
   所以就当1GB内存最多可以统计1千万数据，所以可以将40亿数据的文件拆分400个小文件   
   **过程**：按行读取40亿文件的每个数据，并放入到内存的哈希表中，用哈希表统计每个数字出现的词频，
   一次统计1千万的数据，然后使用哈希函数对统计的每个数据进行哈希并对400取模，这样就将每个数据哈希到不同
   的小文件中，因为哈希哈数的离散型和均匀性，基本可以保证每个文件都是1千万个数据（如果40亿数据每个都是不同的话），
   将40亿的数据都拆分到不同的小文件之后（可以保证相同的元素必定在同一个文件中），然后统计每个小文件中每个数据出现的词频
   合并出现相同的数据的词频，然后记录每个文件出现次数最多的数据，对400个文件都重复这样操作，就可以得到400个出现次数最多
   的数据，找到其中出现次数最多的数据接口。


### 问题二：位图问题（5）
- 32位无符号整数的范围时0~4294967295，现在有一个正好包含40亿个无符号整数的文件，
所以在整个范围中必然存在没出现过的数。可以使用最多1GB的内存，怎么找到所有未出现过的数？   
   - **方法一**：使用布隆过滤器，先将所有的数据放入到布隆过滤器中，然后从0~4294967295开始遍历，
   查询每个数是否都在布隆过滤器中。
   > 布隆过滤器的方式可行，但是如果不允许出现误差，那么就不可以使用。
   
   - **方法二**： 使用位数组进行统计，因为1B有8比特，那么1GB包含80亿比特。创建一个2^32长度的比特数组，
   然后遍历40亿的整数，将每个数对应的比特位设置为1，那么遍历一遍之后，没有设置为1的数据就是没有出现的数据，
   遍历一遍比特数组，就可以知道所有没有出现的数据。
```java
    // 使用整型数组表示比特数组
    int[] arr = new int[10];
    // arr[0] 是一个int类型，有32位，0~31 范围的比特
    // arr[1] 是一个int类型，有32位，表示32~63 范围比特
    // arr[2] 表示64~95 范围的比特
    
    // 计算每个数应该标记的比特位置
    int i = 100; //以100这个整数为例，100对应的比特数组的下标
    arr[i / 32] = arr[i / 32] | (1 << (i % 32)); // 将位数组的指定位置标记为1
    
    // 判断一个数是否出现过
    int status = (arr[i / 32] & (1 << (i % 32))) == 0 ? 0 : 1;
    if(status == 1) {
       System.out.println("i = " + i + "出现过");
    } else {
        System.out.println("i = " + i + "没有出现过");
    }
  ```

### 题目三：哈希问题
- 问题一：有一个包含100亿个URL的大文件，假设每个URL占用64B,请找出其中所有重复的URL
    - **方法一**：布隆过滤器，不过有误差
    - **方法二**：准备1000个小文件，然后对原始文件按行读取，并通过哈希函数将每个URL分派到不同的小文件中，
    这样就可以将大问题转换为数据规模较小的问题，如果当前拆分出来的小文件依然比当前得内存大，那么对这个小文件
    继续使用哈希函数进行拆分，例如可以拆分为100个小文件，因为使用的是哈希函数，所以相同的URL总是在同一个文件，
    拆分之后就可以将小文件直接加载到内存中，统计每个小文件中出现的重复的URL。
> 利用哈希函数将大规模问题转换为小规模问题。MapReduce

- 问题二：查询重复出现URL的前100名，topK问题  
    第一步：准备100个小文件，按行读取原文件，并对每个URL进行哈希取模，分派到不同的小文件   
    第二步：统计每个小文件中URL的词频，并且每个小文件保存的是前100个出现次数最多的数   
    第三步：如果内存允许，将100个小文件的前100名出现最多的URL放入内存那种排序，就可以得到top100,
    如果内存不允许放入这么多数据，就将100个文件的每个最大URL放入内存，并将最大的输出到新文件中，然后从该文件
    重新加载一个URL及出现次数进行排（归并排序）。

### 题目四：分段统计 + 位图
- 32位无符号整数的范围是0~4294967295，现在有40亿个无符号整数，可以使用最多1GB的内存，
找出所有出现了2次的数   
    - 第一步：使用位数组中的2个比特位记录一个数和出现的次数，例如 0 1 这两个比特位用来记录整数0出现的次数，2 3这两比特位用来记录1出现的次数，  
      如果0 1这两个比特位是00，那么就表示整数0出现0次   
      如果0 1这两个比特位是01，表示整数0出现1次   
      如果0 1这两个比特位是10，表示整数0出现2次   
      如果0 1这两个比特位是11，表示整数0出现3次及以上   
      然后将每个数都标记到比特数组上，因为如果使用2个比特位来统计，1GB不能放入40亿的数，
    - 第二步：因为无法放下，那么需要进行分段统计，先统计2^31次方个数出现的次数，然后将位数组释放内存，
    然后统计剩下的2^31次方的数据。

### 题目五：堆、外排序处理
- 32位无符号整数的范围时0~4294967295，有一个10G大小的文件，每一行都装着这种类型的数字，
整个文件是无序的，给你5G（或只能装3个数）的内存空间，请你输出一个10G大小的文件，就是原文件所有数字排序的结果
    - **堆**：在内存中维护一个大根堆，这个大根堆的大小根据给定的内存进行控制，按行读取原文件，如果当前的数比
    大根堆的堆顶小，那么进入大根堆，然后调整大根堆，遍历一遍原文件之后，得到一个包含了前n个最小数的大根堆,大根堆中
    保存的是整数和整数出现的词频，然后将这n个数按照大小并以依次输出到新的文件中，有多少词频就输出多少次。
    并使用一个变量记录当前大根堆中最大的数，然后重复上述步骤，重新开始遍历原始文件，统计时增加判断条件：原文件中小于等于变量记录的数不进行统计
    这样每次都得到最小得前n个数，最终完成排序
    
    - **外排序**：将10G的文件拆分为2个5G的小文件，然后将每个小文件加载到内存中进行排序，先将每个小文件自身排好序，
    然后利用外排的性质，取两个文件的前n个小（大）数，放入到内存中进行排序，并将最小(最大)数输出到新的文件中，直到某一个文件读取到内存的数
    已经完全输出到新的文件了，然后从这个文件中重新读取n个数放入到内存中排序，重复上述步骤，最终将所有的数输出到新的文件完成排序。
    
      
